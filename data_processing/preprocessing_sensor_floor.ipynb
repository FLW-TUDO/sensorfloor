{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib.font_manager import json_dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------\n",
    "# Dataset files\n",
    "# -----------------------------------------------\n",
    "dataset_path = \"/home/gouda/sensorfloor/datasets/debugging_data\"\n",
    "sensorfloor_json_file = \"sensorfloor_data.txt\"\n",
    "vicon_json_files = [\"vicon_data_person_1.txt\", \"vicon_data_person_3.txt\"]\n",
    "vicon_object_names = [\"person_1\", \"person_3\"]\n",
    "dataset_type = \"train\"  # train or test\n",
    "# -----------------------------------------------\n",
    "\n",
    "sensorfloor_json_file = os.path.join(dataset_path, sensorfloor_json_file)\n",
    "vicon_json_files = [os.path.join(dataset_path, vicon_json_file) for vicon_json_file in vicon_json_files]\n",
    "num_of_vicon_objects = len(vicon_json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data = []\n",
    "\n",
    "# txt file is not well formated json, it must be read line by line\n",
    "for line in open(sensorfloor_json_file, \"r\"):\n",
    "    sf_data.append(json.loads(line))\n",
    "\n",
    "df_sf = pd.DataFrame(sf_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataframe of sensor floors ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Timestamp Interpolation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test timestamp interpolation\n",
    "#t_batch_i_now = np.zeros((23,15))\n",
    "t_batch_i_old = np.zeros((23,15))\n",
    "df_sf_buf = df_sf.copy()\n",
    "\n",
    "\n",
    "#df_sf_buf = df_sf_buf.reindex(df_sf_buf.columns.tolist() + ['ax','ay','az','gx','gy','gz','mx','my','mz','rssi'], axis=1) \n",
    "out = []\n",
    "for index, row in df_sf_buf.T.items():\n",
    "    index_strip_id = int(df_sf_buf['column_num'][index])\n",
    "    index_node_id = int(df_sf_buf['node_id'][index])\n",
    "    #print('t_batch: ', df_sf_buf['timestamp'][index])\n",
    "    #t_batch_i_now[index_strip_id][index_node_id] = df_sf_buf['timestamp'][index]\n",
    "    #print(t_batch_i_old[index_strip_id-1][index_node_id-1])\n",
    "    delta_t = 0\n",
    "    timestamp_i = 0\n",
    "\n",
    "    for i in range(len(df_sf_buf['data'][index])):\n",
    "\n",
    "        # set previous timestamp\n",
    "        if t_batch_i_old[index_strip_id-1][index_node_id-1] == 0:  # first sample has no previous timestamp, set it to around 4 seconds before\n",
    "            delta_t = 4/19\n",
    "            t_i = (df_sf_buf['timestamp'][index]-4) + ((1+i)*delta_t)\n",
    "        elif t_batch_i_old[index_strip_id-1][index_node_id-1] < df_sf_buf['timestamp'][index] and t_batch_i_old[index_strip_id-1][index_node_id-1] > 0:\n",
    "            delta_t = (df_sf_buf['timestamp'][index] - t_batch_i_old[index_strip_id-1][index_node_id-1])/len(df_sf_buf['data'][index])\n",
    "            t_i = t_batch_i_old[index_strip_id-1][index_node_id-1] + ((1+i)*delta_t)\n",
    "            \n",
    "        if df_sf_buf['data'][index][i]['r'][0] < 0:\n",
    "            rssi_val = df_sf_buf['data'][index][i]['r'][0]\n",
    "        else:\n",
    "            rssi_val = np.nan\n",
    "            #print('iter > 0: ', delta_t)\n",
    "\n",
    "        out.append({'strip_id':df_sf_buf['column_num'][index],'node_id':df_sf_buf['node_id'][index],\n",
    "            'ax':df_sf_buf['data'][index][i]['a'][0], 'ay':df_sf_buf['data'][index][i]['a'][1], 'az':df_sf_buf['data'][index][i]['a'][2],\n",
    "            'gx':df_sf_buf['data'][index][i]['g'][0], 'gy':df_sf_buf['data'][index][i]['g'][1], 'gz':df_sf_buf['data'][index][i]['g'][2],\n",
    "            'mx':df_sf_buf['data'][index][i]['m'][0], 'my':df_sf_buf['data'][index][i]['m'][1], 'mz':df_sf_buf['data'][index][i]['m'][2],\n",
    "            'r':rssi_val, 'timestamp':t_i})\n",
    "\n",
    "        #print(out[index]['strip_id'], out[index]['node_id'],'t_old: ', t_batch_i_old[index_strip_id-1][index_node_id-1], 't_now: ', df_sf_buf['timestamp'][index], out[index]['timestamp'])\n",
    "        t_first = (df_sf_buf['timestamp'][index]) - 4           \n",
    "        t_batch_i_old[index_strip_id-1][index_node_id-1] = t_first\n",
    "        #print(t_batch_i_old[index_strip_id-1][index_node_id-1])\n",
    "    \n",
    "    \n",
    "    t_batch_i_old[index_strip_id-1][index_node_id-1] = df_sf_buf['timestamp'][index]    \n",
    "    #print(out[index]['strip_id'], out[index]['node_id'],'t_old: ', t_batch_i_old[index_strip_id-1][index_node_id-1], 't_now: ', df_sf_buf['timestamp'][index], out[index]['timestamp'])\n",
    "        \n",
    "\n",
    "df_sf_final = pd.DataFrame(out)\n",
    "del(out)\n",
    "df_sf_final = df_sf_final.sort_values(['timestamp'])\n",
    "df_sf_final = df_sf_final.reset_index(drop=True)\n",
    "df_sf_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Dataset of VICON Coordinates**\n",
    "\n",
    "Only the first object of VICON will be loaded here. This first object will be used to synchronize the VICON to the Sensorfloor data.\n",
    "Other VICON objects will be synchronized to this first object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET OF VICON COORDINATES\n",
    "\n",
    "def load_vicon_json(vicon_json_file):\n",
    "    vicon_data = []\n",
    "    for line in open(vicon_json_file, \"r\"):\n",
    "        vicon_data.append(json.loads(line))\n",
    "\n",
    "    df_vicon = pd.DataFrame(vicon_data)\n",
    "    #df_vicon['time'] = pd.to_datetime(df_vicon['time'],unit='s')\n",
    "    df_vicon.shape\n",
    "    df_vicon_buf = df_vicon.copy()\n",
    "    df_vicon_buf = df_vicon_buf.reindex(df_vicon_buf.columns.tolist() + ['X','Y'], axis=1) \n",
    "\n",
    "    for index, row in df_vicon_buf.T.items():\n",
    "        for i in range(len(df_vicon_buf['translation'][index])):\n",
    "            #print((test_df['data'][index][i]['r']))\n",
    "            df_vicon_buf.loc[index,'X'] = df_vicon_buf['translation'][index][0]\n",
    "            df_vicon_buf.loc[index,'Y'] = df_vicon_buf['translation'][index][1]\n",
    "\n",
    "    df_vicon_buf = df_vicon_buf.drop(columns=['object','translation','rotation'])\n",
    "\n",
    "    return df_vicon_buf\n",
    "\n",
    "df_vicon_buf = load_vicon_json(vicon_json_files[0])\n",
    "df_vicon_buf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Filter and Resample Vicon Data***\n",
    "\n",
    "Only the first object will be resampled. Other VICON objects will choose closest samples in time to thses samples time stamps of the first VICON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_vicon(df_vicon_buf, resample=False):\n",
    "    df_vicon_resample = df_vicon_buf.copy()\n",
    "    df_vicon_resample['time_resample'] = pd.to_datetime(df_vicon_resample['time'],unit='s')\n",
    "    #df_vicon_resample['time'] = df_vicon_resample['time'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "    df_vicon_resample = df_vicon_resample.set_index('time_resample')\n",
    "    df_vicon_final = df_vicon_resample.resample('40ms').ffill()\n",
    "    df_vicon_final = df_vicon_final.dropna()\n",
    "    df_vicon_final = df_vicon_final.sort_values(['time'])\n",
    "    df_vicon_final = df_vicon_final.reset_index(drop=True)\n",
    "    return df_vicon_final\n",
    "\n",
    "df_vicon_final = resample_vicon(df_vicon_buf)\n",
    "df_vicon_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE ARRAY OF RSSI & VICON COORDINATES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import width\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib ipympl\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "#CREATE DATASET FOR SENSOR FLOOR ARRAY\n",
    "x_sf = df_sf_final['strip_id'].to_numpy()\n",
    "y_sf = df_sf_final['node_id'].to_numpy()\n",
    "z_sf = df_sf_final['r'].to_numpy()\n",
    "t_sf = df_sf_final['timestamp'].to_numpy()\n",
    "dataSet_sf = np.array([x_sf, y_sf, z_sf, t_sf])\n",
    "numDataPoints_sf = len(t_sf)\n",
    "num_of_nodes = 15\n",
    "num_of_strips = 23\n",
    "\n",
    "delta_t_sf = round((t_sf.max()-t_sf.min())/numDataPoints_sf, 6)\n",
    "\n",
    "print('dataset sf: ', dataSet_sf.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#CREATE DATASET FOR VICON COORDINATES\n",
    "t_vc = df_vicon_final['time'].to_numpy()\n",
    "x_vc = df_vicon_final['X'].to_numpy()\n",
    "y_vc = df_vicon_final['Y'].to_numpy()\n",
    "dataSet_vc = np.array([x_vc, y_vc, t_vc])\n",
    "numDataPoints_vc = len(t_vc)\n",
    "\n",
    "delta_t_vc = round((t_vc.max()-t_vc.min())/numDataPoints_vc, 6)\n",
    "\n",
    "print(\"dataset vc:\", dataSet_vc.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------#\n",
    "#Check the index of closest timestamp to Vicon Dataset\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    #print(np.abs(array - value), len(np.abs(array - value)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "#closest_index_vicon = []\n",
    "closest_index_sf = []\n",
    "\n",
    "\n",
    "for i in range(numDataPoints_vc):\n",
    "    pos = t_vc[i]\n",
    "    #index_vicon = find_nearest(dataSet_vc[2], pos)\n",
    "    index_sf = find_nearest(dataSet_sf[3], pos)\n",
    "\n",
    "    #closest_index_vicon.append(index_vicon)\n",
    "    closest_index_sf.append(index_sf)\n",
    "\n",
    "print(len(closest_index_sf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE FRAME FOR MERGED DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE ARRAY FOR DATA SENSORS\n",
    "#from asyncio.windows_events import NULL\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# path = \"D:/Arbeit/6GEM/Program_Development/Sensorfloor/SensorFloor_Evaluation_Tool\"\n",
    "# os.chdir(path)\n",
    "\n",
    "KEYS = ['ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz', 'r', 'timestamp']\n",
    "Vicon_Coords = pd.read_csv(\"vicon_node_positions.csv\")\n",
    "df_data = Vicon_Coords[['strip_id','node_id']]\n",
    "df_data = df_data.astype('int32')\n",
    "\n",
    "X = np.zeros([len(closest_index_sf), 23, 15, 11])\n",
    "t = np.zeros([len(closest_index_sf), 1])\n",
    "frames = []\n",
    "dataSet_vc_X = []\n",
    "dataSet_vc_Y = []\n",
    "dataSet_vc_t = []\n",
    "cnt = 0\n",
    "X_i = np.zeros([23, 15, 11])\n",
    "\n",
    "for index, row in tqdm(df_sf_final.T.items(), total=len(df_sf_final)):\n",
    "\n",
    "    df_i = row\n",
    "\n",
    "    for i, key in enumerate(KEYS):\n",
    "        X_i[int(df_i.strip_id) - 1, int(df_i.node_id) - 1, i] = df_i[key]\n",
    "    \n",
    "    X_df = X_i.reshape([345,11])\n",
    "    df_X = pd.DataFrame(X_df, columns=KEYS)\n",
    "    df_data[['ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz', 'r', 'timestamp']] = df_X\n",
    "    frame_i = df_data.to_json(orient='columns')\n",
    "    \n",
    "    t_i = df_i.timestamp\n",
    "\n",
    "    # X[index] = X_i\n",
    "    # t[index] = t_i\n",
    "    #frames.insert(index, frame_i)\n",
    "    frame_bool = df_data.empty\n",
    "    #print(frame_bool)\n",
    "\n",
    "    if index in closest_index_sf and not frame_bool:\n",
    "       \n",
    "        #print(df_data)\n",
    "        index_assoc = closest_index_sf.index(index)\n",
    "        #print(cnt, index, index_assoc)\n",
    "        frames.append(frame_i)\n",
    "        #frames[cnt] = frame_i\n",
    "        X[cnt] = X_i\n",
    "        t[cnt] = t_i\n",
    "        dataSet_vc_X.append(dataSet_vc[0,index_assoc])\n",
    "        dataSet_vc_Y.append(dataSet_vc[1,index_assoc])\n",
    "        dataSet_vc_t.append(dataSet_vc[2,index_assoc])\n",
    "        #dataSet_vc_final.append(dataSet_vc[:,index_assoc])\n",
    "        #print(dataSet_vc[0,index_assoc],dataSet_vc[1,index_assoc],dataSet_vc[2,index_assoc])\n",
    "\n",
    "        # frames[index_assoc] = frame_i\n",
    "        # X[index_assoc] = X_i\n",
    "        # t[index_assoc] = t_i\n",
    "        cnt += 1\n",
    "    #print(index,'/',len(df_sf_final))\n",
    "\n",
    "dataSet_vc_final = np.array([dataSet_vc_X, dataSet_vc_Y, dataSet_vc_t])\n",
    "print(X.shape, t.shape, len(frames), dataSet_vc_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check index of timestamp threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data_final = X[:cnt-1]\n",
    "t_data_final = t[:cnt-1]\n",
    "frames_final = frames[:cnt-1]\n",
    "\n",
    "#dataSet_vc_final = dataSet_vc[:,:]\n",
    "dataSet_vc_final = dataSet_vc_final[:,:-1]\n",
    "dataSet_vc_final = np.transpose(dataSet_vc_final)\n",
    "\n",
    "#print(index_low_X, t[index_low_X] , index_low_vc, dataSet_vc[2][index_low_vc])\n",
    "print(sensor_data_final.shape, t_data_final.shape, len(frames_final), dataSet_vc_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read and synchronize other VICON objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json files of other vicon objects\n",
    "other_vicon_obj_filtered_data = []\n",
    "for i in range(1, num_of_vicon_objects):\n",
    "    obj_df = load_vicon_json(vicon_json_files[i])\n",
    "    obj_df = resample_vicon(obj_df, resample=True)\n",
    "\n",
    "    obj_t_vc = obj_df['time'].to_numpy()\n",
    "    obj_x_vc = obj_df['X'].to_numpy()\n",
    "    obj_y_vc = obj_df['Y'].to_numpy()\n",
    "\n",
    "    # find the closest timestamps in these other objects to the same timestamps of the first vicon object\n",
    "    closest_index_vicon = []\n",
    "    for i in range(len(dataSet_vc_final[:,2])):\n",
    "        pos = dataSet_vc_final[:,2][i]\n",
    "        index_vicon = find_nearest(obj_t_vc, pos)\n",
    "        closest_index_vicon.append(index_vicon)\n",
    "\n",
    "    obj_vicon_data = np.array([obj_x_vc[closest_index_vicon], obj_y_vc[closest_index_vicon], obj_t_vc[closest_index_vicon]])\n",
    "    \n",
    "    other_vicon_obj_filtered_data.append(obj_vicon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(dataSet_vc[0], dataSet_vc[1], 'r', label='Vicon Object 1')\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(other_vicon_obj_filtered_data[0][0], other_vicon_obj_filtered_data[0][1], 'r', label='Vicon Object 2')\n",
    "plt.show()\n",
    "\n",
    "print(dataSet_vc[0].shape, other_vicon_obj_filtered_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MERGE RSSI HEATMAP & VICON COORDINATES WITH SLIDER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE RSSI HEATMAP & VICON COORDINATES WITH SLIDER\n",
    "from turtle import width\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib ipympl\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "rssi_data = sensor_data_final[:,:,:,9]\n",
    "rssi_data_transpose = np.transpose(rssi_data, [0,2,1])\n",
    "\n",
    "numdataPoints = len(dataSet_vc_final)\n",
    "\n",
    "# GET SOME MATPLOTLIB OBJECTS\n",
    "#fig, (ax1, ax2) = plt.subplots(figsize=(10,12), nrows=2)\n",
    "fig = plt.figure(figsize=(12,14))\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "# AXES PROPERTIES RSSI HEATMAP\n",
    "ax1 = fig.add_subplot(311) #(row, column, pos)\n",
    "#ax1.set_autoscale_on\n",
    "ax1.set_xlabel('Strip ID')\n",
    "ax1.set_ylabel('Node ID')\n",
    "ax1.set_title('RSSI Heatmap')\n",
    "\n",
    "# AXES PROPERTIES VICON COORDINATES\n",
    "object_vc_final = other_vicon_obj_filtered_data[0].transpose()\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.set_xlim(-11.185, 10.185)\n",
    "ax2.set_ylim(-6.425, 7.575)\n",
    "ax2.set_xlabel('X(t)')\n",
    "ax2.set_ylabel('Y(t)')\n",
    "ax2.set_title('Vicon object: ' + vicon_object_names[0])\n",
    "\n",
    "# AXES PROPERTIES VICON COORDINATES\n",
    "ax3 = fig.add_subplot(313)\n",
    "ax3.set_xlim(-11.185, 10.185)\n",
    "ax3.set_ylim(-6.425, 7.575)\n",
    "ax3.set_xlabel('X(t)')\n",
    "ax3.set_ylabel('Y(t)')\n",
    "ax3.set_title('Vicon object: ' + vicon_object_names[1])\n",
    "\n",
    "\n",
    "# Defining the Slider button\n",
    "# xposition, yposition, width and height\n",
    "# ax_slide_sf = plt.axes([0.155, 0.02, 0.65, 0.03])\n",
    "# ax_slide_vc = plt.axes([0.155, 0.07, 0.65, 0.03])\n",
    "ax_slide_merge = plt.axes([0.155, 0.12, 0.65, 0.03])\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    #print(np.abs(array - value), len(np.abs(array - value)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "#DISPLAY INITIAL IMAGE\n",
    "im_h = ax1.imshow(rssi_data_transpose[numdataPoints-1], cmap=\"YlGnBu\", aspect='auto')\n",
    "axins = inset_axes(ax1,\n",
    "                   width=\"1%\",  # width = 5% of parent_bbox width\n",
    "                   height=\"90%\",  # height : 50%\n",
    "                   loc='lower left',\n",
    "                   bbox_to_anchor=(1.05, 1.25, 1, 1),\n",
    "                   bbox_transform=ax2.transAxes,\n",
    "                   borderpad=0,\n",
    "                   )\n",
    "cbar = plt.colorbar(im_h, cax=axins, ax=ax1)\n",
    "cbar.set_label(label='RSSI (dBm)', size=15)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "\n",
    "#cbar.ax.set_axes_locator\n",
    "# #cbar.set_ticks()\n",
    "\n",
    "line1 = ax2.plot(dataSet_vc_final[:,0], dataSet_vc_final[:,1], lw=2, c='g')[0] # For line plot\n",
    "line2 = ax3.plot(object_vc_final[:,0], object_vc_final[:,1], lw=2, c='g')[0] # For line plot\n",
    "\n",
    "# Properties of the sliderdf_vicon_final = df_vicon_final.sort_values(['time'])\n",
    "df_vicon_final = df_vicon_final.reset_index(drop=True)\n",
    "\n",
    "#normal data\n",
    "timestamp_merge = Slider(ax_slide_merge, 'Timestamp (s)',\n",
    "                  t_vc.min(), t_vc.max(), valinit=t_vc.min(), valstep=delta_t_vc)\n",
    "\n",
    " \n",
    "\n",
    "def update_all(val):\n",
    "    pos = timestamp_merge.val\n",
    "    #print(pos)\n",
    "    index = find_nearest(dataSet_vc_final[:,2], pos)\n",
    "    line1.set_xdata(dataSet_vc_final[:index,0])\n",
    "    line1.set_ydata(dataSet_vc_final[:index,1])\n",
    "\n",
    "    index = find_nearest(object_vc_final[:,2], pos)\n",
    "    line2.set_xdata(object_vc_final[:index,0])\n",
    "    line2.set_ydata(object_vc_final[:index,1])\n",
    "\n",
    "    #index2 = find_nearest(dataSet_sf[3], dataSet_vc_final[2][index])\n",
    "    im_h.set_data(rssi_data_transpose[index])\n",
    "\n",
    "    #redrawing the figure\n",
    "    fig.canvas.draw() \n",
    "\n",
    "# Calling the function \"update\" when the value of the slider is changed\n",
    "\n",
    "timestamp_merge.on_changed(update_all)\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(left=0.1, bottom=0.2, right=0.88, top=0.97, hspace=0.2)\n",
    "#plt.subplots_adjust(left=0.155, bottom=0.2, right=0.91, top=0.97, hspace=0.2)\n",
    "#plt.subplot_tool()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(dataset_path, 'visualization.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE DATASET\n",
    "\n",
    "#dataSet_vc_final = np.transpose(dataSet_vc_final)\n",
    "frame_number = np.empty(dataSet_vc_final.shape[0], dtype=object)\n",
    "frame_data = np.empty(dataSet_vc_final.shape[0], dtype=object)\n",
    "frame_count = 0\n",
    "for row in range(dataSet_vc_final.shape[0]):\n",
    "    time_vc = dataSet_vc_final[row][2]\n",
    "    #time_vc = dataSet_vc[2][row]\n",
    "    #index_vc = closest_timestamp(dataSet_vc[2], time_vc)\n",
    "    #index_sf = closest_timestamp(t_data_final, time_vc)\n",
    "\n",
    "    frame_number[row] = str(frame_count)\n",
    "    frame_data[row] = frames_final[row]\n",
    "    frame_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATES THE DATASET AS .CSV FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_objects_data = []\n",
    "column_names = []\n",
    "if num_of_vicon_objects > 1:\n",
    "    for obj_num in range(0, num_of_vicon_objects-1):\n",
    "        obj_filtered_data = other_vicon_obj_filtered_data[obj_num].transpose()\n",
    "        other_objects_data.append(obj_filtered_data[:,0])\n",
    "        column_names.append('vicon_' + str(obj_num+1) + '_x')\n",
    "        other_objects_data.append(obj_filtered_data[:,1])\n",
    "        column_names.append('vicon_' + str(obj_num+1) + '_y')\n",
    "\n",
    "if dataset_type == \"train\":\n",
    "    array_frame_vc = dataSet_vc_final.astype(object)\n",
    "\n",
    "    dataSet_final = np.array([frame_number, frame_data, array_frame_vc[:,0], array_frame_vc[:,1]] + other_objects_data)\n",
    "    dataSet_final = np.transpose(dataSet_final)\n",
    "\n",
    "    frame_sf = pd.DataFrame(dataSet_final, columns=['frame_number', 'data', 'vicon_0_x','vicon_0_y'] + column_names)\n",
    "\n",
    "    frame_sf.to_csv(os.path.join(dataset_path, 'train_processed_dataset_objects_' + str(num_of_vicon_objects) + '.csv'), index=False)\n",
    "\n",
    "# elif dataset_type == \"test\":\n",
    "#     array_frame_vc = dataSet_vc_final.astype(object)\n",
    "\n",
    "#     test_dataset = np.array([frame_number, frame_data])\n",
    "#     test_dataset = np.transpose(test_dataset)\n",
    "\n",
    "#     ground_truth = np.array([frame_number, array_frame_vc[:,2], array_frame_vc[:,0], array_frame_vc[:,1]])\n",
    "#     ground_truth = np.transpose(ground_truth)\n",
    "\n",
    "#     frame_test = pd.DataFrame(test_dataset, columns=['frame_number','data'])\n",
    "#     frame_ground_truth = pd.DataFrame(ground_truth, columns=['frame_number','time','vicon_x','vicon_y'])\n",
    "\n",
    "#     path_dataset = '/media/irfan-flw/DATA/Arbeit/6GEM/Program_Development/6GEM_Dataset/Dataset_Sensor_Floor_Final/24102022/'\n",
    "\n",
    "#     frame_test.to_csv(os.path.join(dataset_path, 'test_processed_dataset.csv'), index=False)\n",
    "#     frame_ground_truth.to_csv(os.path.join(dataset_path, 'test_with_gt_processed_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store the data to pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # write data\n",
    "# pickle_data = [sensor_data_final, dataSet_vc_final, t_data_final]\n",
    "# with open(os.path.join(dataset_path, \"dataset.pkl\"), 'wb') as handle:\n",
    "#     pickle.dump(pickle_data, handle, protocol=3)\n",
    "# print('Successfully stored!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
