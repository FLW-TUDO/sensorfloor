{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib.font_manager import json_dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "  \n",
    "\n",
    "sf_data = []\n",
    "vicon_data = []\n",
    "#dataset_name = \"test_data\"\n",
    "#path_sf = \"D:/Arbeit/6GEM/Program_Development/6GEM_Dataset/sensorfloor_measurement/24102022\"\n",
    "#file_name_sf = \"sensor_floor_data_24102022_\" + dataset_name + \".txt\"\n",
    "file_name_sf = \"current_data/test_before_workshop/test_data.txt\"\n",
    "#os.chdir(path_sf)\n",
    "\n",
    "#for line in open(\"../Dataset_sensor_floor/sensorfloor_measurement/16092022/sensor_floor_data_16092022_\" + dataset_name + \".txt\", \"r\"):\n",
    "#for line in open(\"../../../media/irfan-flw/OS/Arbeit/6GEM/Program_Development/6GEM_Dataset/sensorfloor_measurement/16092022/sensor_floor_data_16092022_\" + dataset_name + \".txt\", \"r\"):\n",
    "for line in open(file_name_sf, \"r\"):\n",
    "    sf_data.append(json.loads(line))\n",
    "\n",
    "df_sf = pd.DataFrame(sf_data)\n",
    "df_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataframe of sensor floors ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Timestamp Interpolation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test timestamp interpolation\n",
    "#t_batch_i_now = np.zeros((23,15))\n",
    "t_batch_i_old = np.zeros((23,15))\n",
    "df_sf_buf = df_sf.copy()\n",
    "\n",
    "\n",
    "#df_sf_buf = df_sf_buf.reindex(df_sf_buf.columns.tolist() + ['ax','ay','az','gx','gy','gz','mx','my','mz','rssi'], axis=1) \n",
    "out = []\n",
    "for index, row in df_sf_buf.T.items():\n",
    "    index_strip_id = int(df_sf_buf['column_num'][index])\n",
    "    index_node_id = int(df_sf_buf['node_id'][index])\n",
    "    #print('t_batch: ', df_sf_buf['timestamp'][index])\n",
    "    #t_batch_i_now[index_strip_id][index_node_id] = df_sf_buf['timestamp'][index]\n",
    "    #print(t_batch_i_old[index_strip_id-1][index_node_id-1])\n",
    "    delta_t = 0\n",
    "    timestamp_i = 0\n",
    "\n",
    "    for i in range(len(df_sf_buf['data'][index])):\n",
    "\n",
    "        #check timestamp\n",
    "        if t_batch_i_old[index_strip_id-1][index_node_id-1] < df_sf_buf['timestamp'][index] and t_batch_i_old[index_strip_id-1][index_node_id-1] > 0:\n",
    "            delta_t = (df_sf_buf['timestamp'][index] - t_batch_i_old[index_strip_id-1][index_node_id-1])/len(df_sf_buf['data'][index])\n",
    "            \n",
    "            t_i = t_batch_i_old[index_strip_id-1][index_node_id-1] + ((1+i)*delta_t)\n",
    "            if df_sf_buf['data'][index][i]['r'][0] < 0:\n",
    "                #print('iter > 0: ', delta_t)\n",
    "                out.append({'strip_id':df_sf_buf['column_num'][index],'node_id':df_sf_buf['node_id'][index],\n",
    "                    'ax':df_sf_buf['data'][index][i]['a'][0],'ay':df_sf_buf['data'][index][i]['a'][1],'az':df_sf_buf['data'][index][i]['a'][2],\n",
    "                    'gx':df_sf_buf['data'][index][i]['g'][0],'gy':df_sf_buf['data'][index][i]['g'][1],'gz':df_sf_buf['data'][index][i]['g'][2],\n",
    "                    'mx':df_sf_buf['data'][index][i]['m'][0],'my':df_sf_buf['data'][index][i]['m'][1],'mz':df_sf_buf['data'][index][i]['m'][2],\n",
    "                    'r':df_sf_buf['data'][index][i]['r'][0],'timestamp':t_i})\n",
    "            else:\n",
    "                out.append({'strip_id':df_sf_buf['column_num'][index],'node_id':df_sf_buf['node_id'][index],\n",
    "                    'ax':df_sf_buf['data'][index][i]['a'][0],'ay':df_sf_buf['data'][index][i]['a'][1],'az':df_sf_buf['data'][index][i]['a'][2],\n",
    "                    'gx':df_sf_buf['data'][index][i]['g'][0],'gy':df_sf_buf['data'][index][i]['g'][1],'gz':df_sf_buf['data'][index][i]['g'][2],\n",
    "                    'mx':df_sf_buf['data'][index][i]['m'][0],'my':df_sf_buf['data'][index][i]['m'][1],'mz':df_sf_buf['data'][index][i]['m'][2],\n",
    "                    'r':np.nan,'timestamp':t_i})\n",
    "                #print(out[index]['strip_id'], out[index]['node_id'],'t_old: ', t_batch_i_old[index_strip_id-1][index_node_id-1], 't_now: ', df_sf_buf['timestamp'][index], out[index]['timestamp'])\n",
    "            # t_batch_i_old[index_strip_id-1][index_node_id-1] = df_sf_buf['timestamp'][index]\n",
    "\n",
    "        elif t_batch_i_old[index_strip_id-1][index_node_id-1] == 0:\n",
    "            delta_t = 4/19\n",
    "            #print('iter 0: ', delta_t)\n",
    "            t_i = (df_sf_buf['timestamp'][index]-4) + ((1+i)*delta_t)\n",
    "            if df_sf_buf['data'][index][i]['r'][0] < 0:\n",
    "                #print(t_i)\n",
    "                out.append({'strip_id':df_sf_buf['column_num'][index],'node_id':df_sf_buf['node_id'][index],\n",
    "                    'ax':df_sf_buf['data'][index][i]['a'][0],'ay':df_sf_buf['data'][index][i]['a'][1],'az':df_sf_buf['data'][index][i]['a'][2],\n",
    "                    'gx':df_sf_buf['data'][index][i]['g'][0],'gy':df_sf_buf['data'][index][i]['g'][1],'gz':df_sf_buf['data'][index][i]['g'][2],\n",
    "                    'mx':df_sf_buf['data'][index][i]['m'][0],'my':df_sf_buf['data'][index][i]['m'][1],'mz':df_sf_buf['data'][index][i]['m'][2],\n",
    "                    'r':df_sf_buf['data'][index][i]['r'][0],'timestamp':t_i})\n",
    "            else:\n",
    "                out.append({'strip_id':df_sf_buf['column_num'][index],'node_id':df_sf_buf['node_id'][index],\n",
    "                    'ax':df_sf_buf['data'][index][i]['a'][0],'ay':df_sf_buf['data'][index][i]['a'][1],'az':df_sf_buf['data'][index][i]['a'][2],\n",
    "                    'gx':df_sf_buf['data'][index][i]['g'][0],'gy':df_sf_buf['data'][index][i]['g'][1],'gz':df_sf_buf['data'][index][i]['g'][2],\n",
    "                    'mx':df_sf_buf['data'][index][i]['m'][0],'my':df_sf_buf['data'][index][i]['m'][1],'mz':df_sf_buf['data'][index][i]['m'][2],\n",
    "                    'r':np.nan,'timestamp':t_i})\n",
    "            #print(out[index]['strip_id'], out[index]['node_id'],'t_old: ', t_batch_i_old[index_strip_id-1][index_node_id-1], 't_now: ', df_sf_buf['timestamp'][index], out[index]['timestamp'])\n",
    "            t_first = (df_sf_buf['timestamp'][index]) - 4           \n",
    "            t_batch_i_old[index_strip_id-1][index_node_id-1] = t_first\n",
    "            #print(t_batch_i_old[index_strip_id-1][index_node_id-1])\n",
    "    \n",
    "    \n",
    "    t_batch_i_old[index_strip_id-1][index_node_id-1] = df_sf_buf['timestamp'][index]    \n",
    "    #print(out[index]['strip_id'], out[index]['node_id'],'t_old: ', t_batch_i_old[index_strip_id-1][index_node_id-1], 't_now: ', df_sf_buf['timestamp'][index], out[index]['timestamp'])\n",
    "        \n",
    "\n",
    "df_sf_final = pd.DataFrame(out)\n",
    "del(out)\n",
    "df_sf_final = df_sf_final.sort_values(['timestamp'])\n",
    "df_sf_final = df_sf_final.reset_index(drop=True)\n",
    "df_sf_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Dataset of VICON Coordinates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET OF VICON COORDINATES\n",
    "#for line in open(\"../Dataset_sensor_floor/vicon_measurement/16092022/vicon_data_16092022_\" + dataset_name + \".txt\", \"r\"):\n",
    "# path_vicon = \"D:/Arbeit/6GEM/Program_Development/6GEM_Dataset/vicon_measurement/24102022\"\n",
    "# file_name_vicon = \"vicon_data_24102022_\" + dataset_name + \".txt\"\n",
    "\n",
    "# os.chdir(path_vicon)\n",
    "file_name_vicon = \"current_data/test_before_workshop/vicon_data_robot_b.txt\"\n",
    "\n",
    "for line in open(file_name_vicon, \"r\"):\n",
    "    vicon_data.append(json.loads(line))\n",
    "\n",
    "df_vicon = pd.DataFrame(vicon_data)\n",
    "#df_vicon['time'] = pd.to_datetime(df_vicon['time'],unit='s')\n",
    "df_vicon.shape\n",
    "df_vicon_buf = df_vicon.copy()\n",
    "df_vicon_buf = df_vicon_buf.reindex(df_vicon_buf.columns.tolist() + ['X','Y'], axis=1) \n",
    "\n",
    "for index, row in df_vicon_buf.T.items():\n",
    "    for i in range(len(df_vicon_buf['translation'][index])):\n",
    "        #print((test_df['data'][index][i]['r']))\n",
    "        df_vicon_buf.loc[index,'X'] = df_vicon_buf['translation'][index][0]\n",
    "        df_vicon_buf.loc[index,'Y'] = df_vicon_buf['translation'][index][1]\n",
    "\n",
    "df_vicon_buf = df_vicon_buf.drop(columns=['object','translation','rotation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Filter and Resample Vicon Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vicon_resample = df_vicon_buf.copy()\n",
    "df_vicon_resample['time_resample'] = pd.to_datetime(df_vicon_resample['time'],unit='s')\n",
    "#df_vicon_resample['time'] = df_vicon_resample['time'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "df_vicon_resample = df_vicon_resample.set_index('time_resample')\n",
    "df_vicon_final = df_vicon_resample.resample('40ms').ffill()\n",
    "df_vicon_final = df_vicon_final.dropna()\n",
    "df_vicon_final = df_vicon_final.sort_values(['time'])\n",
    "df_vicon_final = df_vicon_final.reset_index(drop=True)\n",
    "df_vicon_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE ARRAY OF RSSI & VICON COORDINATES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import width\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib ipympl\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "#CREATE DATASET FOR SENSOR FLOOR ARRAY\n",
    "x_sf = df_sf_final['strip_id'].to_numpy()\n",
    "y_sf = df_sf_final['node_id'].to_numpy()\n",
    "z_sf = df_sf_final['r'].to_numpy()\n",
    "t_sf = df_sf_final['timestamp'].to_numpy()\n",
    "dataSet_sf = np.array([x_sf, y_sf, z_sf, t_sf])\n",
    "numDataPoints_sf = len(t_sf)\n",
    "num_of_nodes = 15\n",
    "num_of_strips = 23\n",
    "\n",
    "delta_t_sf = round((t_sf.max()-t_sf.min())/numDataPoints_sf, 6)\n",
    "\n",
    "print('dataset sf: ', dataSet_sf.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#CREATE DATASET FOR VICON COORDINATES\n",
    "t_vc = df_vicon_final['time'].to_numpy()\n",
    "x_vc = df_vicon_final['X'].to_numpy()\n",
    "y_vc = df_vicon_final['Y'].to_numpy()\n",
    "dataSet_vc = np.array([x_vc, y_vc, t_vc])\n",
    "numDataPoints_vc = len(t_vc)\n",
    "\n",
    "delta_t_vc = round((t_vc.max()-t_vc.min())/numDataPoints_vc, 6)\n",
    "\n",
    "print(\"dataset vc:\", dataSet_vc.shape)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------#\n",
    "#Check the index of closest timestamp to Vicon Dataset\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    #print(np.abs(array - value), len(np.abs(array - value)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "#closest_index_vicon = []\n",
    "closest_index_sf = []\n",
    "\n",
    "\n",
    "for i in range(numDataPoints_vc):\n",
    "    pos = t_vc[i]\n",
    "    #index_vicon = find_nearest(dataSet_vc[2], pos)\n",
    "    index_sf = find_nearest(dataSet_sf[3], pos)\n",
    "\n",
    "    #closest_index_vicon.append(index_vicon)\n",
    "    closest_index_sf.append(index_sf)\n",
    "\n",
    "print(len(closest_index_sf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATE FRAME FOR MERGED DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE ARRAY FOR DATA SENSORS\n",
    "#from asyncio.windows_events import NULL\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# path = \"D:/Arbeit/6GEM/Program_Development/Sensorfloor/SensorFloor_Evaluation_Tool\"\n",
    "# os.chdir(path)\n",
    "\n",
    "KEYS = ['ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz', 'r', 'timestamp']\n",
    "Vicon_Coords = pd.read_csv(\"vicon_node_positions.csv\")\n",
    "df_data = Vicon_Coords[['strip_id','node_id']]\n",
    "df_data = df_data.astype('int32')\n",
    "\n",
    "X = np.zeros([len(closest_index_sf), 23, 15, 11])\n",
    "t = np.zeros([len(closest_index_sf), 1])\n",
    "frames = []\n",
    "dataSet_vc_X = []\n",
    "dataSet_vc_Y = []\n",
    "dataSet_vc_t = []\n",
    "cnt = 0\n",
    "X_i = np.zeros([23, 15, 11])\n",
    "\n",
    "for index, row in tqdm(df_sf_final.T.items(), total=len(df_sf_final)):\n",
    "\n",
    "    df_i = row\n",
    "\n",
    "    for i, key in enumerate(KEYS):\n",
    "        X_i[int(df_i.strip_id) - 1, int(df_i.node_id) - 1, i] = df_i[key]\n",
    "    \n",
    "    X_df = X_i.reshape([345,11])\n",
    "    df_X = pd.DataFrame(X_df, columns=KEYS)\n",
    "    df_data[['ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz', 'r', 'timestamp']] = df_X\n",
    "    frame_i = df_data.to_json(orient='columns')\n",
    "    \n",
    "    t_i = df_i.timestamp\n",
    "\n",
    "    # X[index] = X_i\n",
    "    # t[index] = t_i\n",
    "    #frames.insert(index, frame_i)\n",
    "    frame_bool = df_data.empty\n",
    "    #print(frame_bool)\n",
    "\n",
    "    if index in closest_index_sf and not frame_bool:\n",
    "       \n",
    "        #print(df_data)\n",
    "        index_assoc = closest_index_sf.index(index)\n",
    "        #print(cnt, index, index_assoc)\n",
    "        frames.append(frame_i)\n",
    "        #frames[cnt] = frame_i\n",
    "        X[cnt] = X_i\n",
    "        t[cnt] = t_i\n",
    "        dataSet_vc_X.append(dataSet_vc[0,index_assoc])\n",
    "        dataSet_vc_Y.append(dataSet_vc[1,index_assoc])\n",
    "        dataSet_vc_t.append(dataSet_vc[2,index_assoc])\n",
    "        #dataSet_vc_final.append(dataSet_vc[:,index_assoc])\n",
    "        #print(dataSet_vc[0,index_assoc],dataSet_vc[1,index_assoc],dataSet_vc[2,index_assoc])\n",
    "\n",
    "        # frames[index_assoc] = frame_i\n",
    "        # X[index_assoc] = X_i\n",
    "        # t[index_assoc] = t_i\n",
    "        cnt += 1\n",
    "    #print(index,'/',len(df_sf_final))\n",
    "\n",
    "dataSet_vc_final = np.array([dataSet_vc_X, dataSet_vc_Y, dataSet_vc_t])\n",
    "print(X.shape, t.shape, len(frames), dataSet_vc_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check index of timestamp threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_data_final = X[:cnt-1]\n",
    "t_data_final = t[:cnt-1]\n",
    "frames_final = frames[:cnt-1]\n",
    "\n",
    "#dataSet_vc_final = dataSet_vc[:,:]\n",
    "dataSet_vc_final = dataSet_vc_final[:,:-1]\n",
    "dataSet_vc_final = np.transpose(dataSet_vc_final)\n",
    "\n",
    "#print(index_low_X, t[index_low_X] , index_low_vc, dataSet_vc[2][index_low_vc])\n",
    "print(sensor_data_final.shape, t_data_final.shape, len(frames_final), dataSet_vc_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MERGE RSSI HEATMAP & VICON COORDINATES WITH SLIDER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE RSSI HEATMAP & VICON COORDINATES WITH SLIDER\n",
    "from turtle import width\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib ipympl\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "rssi_data = sensor_data_final[:,:,:,9]\n",
    "rssi_data_transpose = np.transpose(rssi_data, [0,2,1])\n",
    "\n",
    "numdataPoints = len(dataSet_vc_final)\n",
    "\n",
    "# GET SOME MATPLOTLIB OBJECTS\n",
    "#fig, (ax1, ax2) = plt.subplots(figsize=(10,12), nrows=2)\n",
    "fig = plt.figure(figsize=(12,14))\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "# AXES PROPERTIES RSSI HEATMAP\n",
    "ax1 = fig.add_subplot(211) #(row, column, pos)\n",
    "#ax1.set_autoscale_on\n",
    "ax1.set_xlabel('Strip ID')\n",
    "ax1.set_ylabel('Node ID')\n",
    "ax1.set_title('RSSI Heatmap')\n",
    "\n",
    "# # AXES PROPERTIES VICON COORDINATES\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.set_xlim(-11.185, 10.185)\n",
    "ax2.set_ylim(-6.425, 7.575)\n",
    "ax2.set_xlabel('X(t)')\n",
    "ax2.set_ylabel('Y(t)')\n",
    "ax2.set_title('Trajectory of robot')\n",
    "\n",
    "\n",
    "# Defining the Slider button\n",
    "# xposition, yposition, width and height\n",
    "# ax_slide_sf = plt.axes([0.155, 0.02, 0.65, 0.03])\n",
    "# ax_slide_vc = plt.axes([0.155, 0.07, 0.65, 0.03])\n",
    "ax_slide_merge = plt.axes([0.155, 0.12, 0.65, 0.03])\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    #print(np.abs(array - value), len(np.abs(array - value)))\n",
    "    return idx\n",
    "\n",
    "\n",
    "#DISPLAY INITIAL IMAGE\n",
    "im_h = ax1.imshow(rssi_data_transpose[numdataPoints-1], cmap=\"YlGnBu\", aspect='auto')\n",
    "axins = inset_axes(ax1,\n",
    "                   width=\"1%\",  # width = 5% of parent_bbox width\n",
    "                   height=\"90%\",  # height : 50%\n",
    "                   loc='lower left',\n",
    "                   bbox_to_anchor=(1.05, 1.25, 1, 1),\n",
    "                   bbox_transform=ax2.transAxes,\n",
    "                   borderpad=0,\n",
    "                   )\n",
    "cbar = plt.colorbar(im_h, cax=axins, ax=ax1)\n",
    "cbar.set_label(label='RSSI (dBm)', size=15)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "\n",
    "#cbar.ax.set_axes_locator\n",
    "# #cbar.set_ticks()\n",
    "\n",
    "line = ax2.plot(dataSet_vc_final[:,0], dataSet_vc_final[:,1], lw=2, c='g')[0] # For line plot\n",
    "\n",
    "# Properties of the slider\n",
    "\n",
    "#normal data\n",
    "timestamp_merge = Slider(ax_slide_merge, 'Timestamp (s)',\n",
    "                  t_vc.min(), t_vc.max(), valinit=t_vc.min(), valstep=delta_t_vc)\n",
    "\n",
    " \n",
    "\n",
    "def update_all(val):\n",
    "    pos = timestamp_merge.val\n",
    "    #print(pos)\n",
    "    index = find_nearest(dataSet_vc_final[:,2], pos)\n",
    "    line.set_xdata(dataSet_vc_final[:index,0])\n",
    "    line.set_ydata(dataSet_vc_final[:index,1])\n",
    "\n",
    "    #index2 = find_nearest(dataSet_sf[3], dataSet_vc_final[2][index])\n",
    "    im_h.set_data(rssi_data_transpose[index])\n",
    "\n",
    "    #redrawing the figure\n",
    "    fig.canvas.draw() \n",
    "\n",
    "# Calling the function \"update\" when the value of the slider is changed\n",
    "\n",
    "timestamp_merge.on_changed(update_all)\n",
    "\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(left=0.1, bottom=0.2, right=0.88, top=0.97, hspace=0.2)\n",
    "#plt.subplots_adjust(left=0.155, bottom=0.2, right=0.91, top=0.97, hspace=0.2)\n",
    "#plt.subplot_tool()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = 'output/plot_img'\n",
    "os.chdir(home_path)\n",
    "plt.savefig('_test_run.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE DATASET\n",
    "\n",
    "#dataSet_vc_final = np.transpose(dataSet_vc_final)\n",
    "frame_number = np.empty(dataSet_vc_final.shape[0], dtype=object)\n",
    "frame_data = np.empty(dataSet_vc_final.shape[0], dtype=object)\n",
    "frame_count = 0\n",
    "for row in range(dataSet_vc_final.shape[0]):\n",
    "    time_vc = dataSet_vc_final[row][2]\n",
    "    #time_vc = dataSet_vc[2][row]\n",
    "    #index_vc = closest_timestamp(dataSet_vc[2], time_vc)\n",
    "    #index_sf = closest_timestamp(t_data_final, time_vc)\n",
    "\n",
    "    frame_number[row] = str(frame_count)\n",
    "    frame_data[row] = frames_final[row]\n",
    "    frame_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATES THE DATASET AS .CSV FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_frame_vc = dataSet_vc_final.astype(object)\n",
    "\n",
    "dataSet_final = np.array([frame_number, array_frame_vc[:,0], array_frame_vc[:,1], frame_data])\n",
    "dataSet_final = np.transpose(dataSet_final)\n",
    "#dataSet_final.shape\n",
    "frame_sf = pd.DataFrame(dataSet_final, columns=['frame_number','vicon_x','vicon_y','data'])\n",
    "\n",
    "path_dataset = '/media/irfan-flw/DATA/Arbeit/6GEM/Program_Development/6GEM_Dataset/Dataset_Sensor_Floor_Final/24102022/'\n",
    "\n",
    "os.chdir(path_dataset)\n",
    "\n",
    "frame_sf.to_csv(r'/media/irfan-flw/DATA/Arbeit/6GEM/Program_Development/6GEM_Dataset/Dataset_Sensor_Floor_Final/24102022/' +  dataset_name + '.csv', index=False)\n",
    "\n",
    "#data_dir = '../Dataset_sensor_floor/Dataset_Final/30092022/'\n",
    "#csv_name = data_dir + 'dataset_3009022_' + dataset_name + '.csv'\n",
    "# csv_name = path_dataset + dataset_name + '.csv'\n",
    "# frame_sf.to_csv(csv_name, index=False)\n",
    "#dataSet_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GENERATES TEST DATASET AS .CSV FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_frame_vc = dataSet_vc_final.astype(object)\n",
    "\n",
    "test_dataset = np.array([frame_number, frame_data])\n",
    "test_dataset = np.transpose(test_dataset)\n",
    "\n",
    "ground_truth = np.array([frame_number, array_frame_vc[:,2], array_frame_vc[:,0], array_frame_vc[:,1]])\n",
    "ground_truth = np.transpose(ground_truth)\n",
    "\n",
    "frame_test = pd.DataFrame(test_dataset, columns=['frame_number','data'])\n",
    "frame_ground_truth = pd.DataFrame(ground_truth, columns=['frame_number','time','vicon_x','vicon_y'])\n",
    "\n",
    "path_dataset = '/media/irfan-flw/DATA/Arbeit/6GEM/Program_Development/6GEM_Dataset/Dataset_Sensor_Floor_Final/24102022/'\n",
    "\n",
    "os.chdir(path_dataset)\n",
    "\n",
    "frame_test.to_csv(r'/media/irfan-flw/DATA/Arbeit/6GEM/Program_Development/6GEM_Dataset/Dataset_Sensor_Floor_Final/28102022/' +  dataset_name + '.csv', index=False)\n",
    "frame_ground_truth.to_csv(r'/media/irfan-flw/DATA/Arbeit/6GEM/Program_Development/6GEM_Dataset/Dataset_Sensor_Floor_Final/28102022/' +  dataset_name + '_gt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_frame_vc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store the data to pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_pickle_file = 'pickle/' + dataset_name + '_24102022.pkl'\n",
    "\n",
    "# write data\n",
    "pickle_data = [sensor_data_final, dataSet_vc_final, t_data_final]\n",
    "with open(data_pickle_file, 'wb') as handle:\n",
    "    pickle.dump(pickle_data, handle, protocol=3)\n",
    "print('Successfully stored!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
